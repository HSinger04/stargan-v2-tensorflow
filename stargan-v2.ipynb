{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQntiASAkVk5"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HSinger04/stargan-v2-tensorflow/blob/master/stargan-v2.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvoSy7kO0RFN"
      },
      "source": [
        "\"\"\"\n",
        "StarGAN v2 TensorFlow Implementation\n",
        "Copyright (c) 2020-present NAVER Corp.\n",
        "\n",
        "This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "4.0 International License. To view a copy of this license, visit\n",
        "http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\"\"\"\n",
        "\n",
        "from utils import *\n",
        "import time\n",
        "from tensorflow.python.data.experimental import AUTOTUNE, prefetch_to_device\n",
        "\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from tqdm.contrib import tenumerate\n",
        "from networks import *\n",
        "from copy import deepcopy\n",
        "import PIL.Image\n",
        "\n",
        "class StarGAN_v2():\n",
        "    def __init__(self, args):\n",
        "        super(StarGAN_v2, self).__init__()\n",
        "\n",
        "        self.model_name = 'StarGAN_v2'\n",
        "        self.phase = args.phase\n",
        "        self.checkpoint_dir = args.checkpoint_dir\n",
        "        self.result_dir = args.result_dir\n",
        "        self.log_dir = args.log_dir\n",
        "        self.sample_dir = args.sample_dir\n",
        "        self.dataset_name = args.dataset\n",
        "        self.augment_flag = args.augment_flag\n",
        "\n",
        "        self.ds_iter = args.ds_iter\n",
        "        self.iteration = args.iteration\n",
        "\n",
        "        self.gan_type = args.gan_type\n",
        "\n",
        "        self.batch_size = args.batch_size\n",
        "        self.print_freq = args.print_freq\n",
        "        self.save_freq = args.save_freq\n",
        "\n",
        "        self.img_size = args.img_size\n",
        "        self.img_ch = args.img_ch\n",
        "\n",
        "        self.lr = args.lr\n",
        "        self.f_lr = args.f_lr\n",
        "        self.beta1 = args.beta1\n",
        "        self.beta2 = args.beta2\n",
        "\n",
        "        self.ema_decay = args.ema_decay\n",
        "\n",
        "        \"\"\" Weight \"\"\"\n",
        "        self.adv_weight = args.adv_weight\n",
        "        self.sty_weight = args.sty_weight\n",
        "        self.ds_weight = args.ds_weight\n",
        "        self.cyc_weight = args.cyc_weight\n",
        "\n",
        "        self.r1_weight = args.r1_weight\n",
        "\n",
        "        \"\"\" Generator \"\"\"\n",
        "        self.latent_dim = args.latent_dim\n",
        "        self.style_dim = args.style_dim\n",
        "        self.num_style = args.num_style\n",
        "\n",
        "        \"\"\" Mapping Network \"\"\"\n",
        "        self.hidden_dim = args.hidden_dim\n",
        "\n",
        "        \"\"\" Discriminator \"\"\"\n",
        "        self.sn = args.sn\n",
        "\n",
        "        self.sample_dir = os.path.join(args.sample_dir, self.model_dir)\n",
        "        check_folder(self.sample_dir)\n",
        "\n",
        "        self.checkpoint_dir = os.path.join(args.checkpoint_dir, self.model_dir)\n",
        "        check_folder(self.checkpoint_dir)\n",
        "\n",
        "        self.log_dir = os.path.join(args.log_dir, self.model_dir)\n",
        "        check_folder(self.log_dir)\n",
        "\n",
        "        self.result_dir = os.path.join(args.result_dir, self.model_dir)\n",
        "        check_folder(self.result_dir)\n",
        "\n",
        "\n",
        "        dataset_path = './dataset'\n",
        "\n",
        "        self.dataset_path = os.path.join(dataset_path, self.dataset_name, 'train')\n",
        "        self.test_dataset_path = os.path.join(dataset_path, self.dataset_name, 'test')\n",
        "        self.domain_list = sorted([os.path.basename(x) for x in glob(self.dataset_path + '/*')])\n",
        "        self.num_domains = len(self.domain_list)\n",
        "\n",
        "        print()\n",
        "\n",
        "        print(\"##### Information #####\")\n",
        "        print(\"# gan type : \", self.gan_type)\n",
        "        print(\"# dataset : \", self.dataset_name)\n",
        "        print(\"# domain_list : \", self.domain_list)\n",
        "\n",
        "        print(\"# batch_size : \", self.batch_size)\n",
        "        print(\"# max iteration : \", self.iteration)\n",
        "        print(\"# ds iteration : \", self.ds_iter)\n",
        "\n",
        "        print()\n",
        "\n",
        "        print(\"##### Generator #####\")\n",
        "        print(\"# latent_dim : \", self.latent_dim)\n",
        "        print(\"# style_dim : \", self.style_dim)\n",
        "        print(\"# num_style : \", self.num_style)\n",
        "\n",
        "        print()\n",
        "\n",
        "        print(\"##### Mapping Network #####\")\n",
        "        print(\"# hidden_dim : \", self.hidden_dim)\n",
        "\n",
        "        print()\n",
        "\n",
        "        print(\"##### Discriminator #####\")\n",
        "        print(\"# spectral normalization : \", self.sn)\n",
        "\n",
        "    ##################################################################################\n",
        "    # Model\n",
        "    ##################################################################################\n",
        "    def build_model(self):\n",
        "        if self.phase == 'train':\n",
        "            \"\"\" Input Image\"\"\"\n",
        "            img_class = Image_data(self.img_size, self.img_ch, self.dataset_path, self.domain_list, self.augment_flag)\n",
        "            img_class.preprocess()\n",
        "\n",
        "            dataset_num = len(img_class.images)\n",
        "            print(\"Dataset number : \", dataset_num)\n",
        "\n",
        "            img_and_domain = tf.data.Dataset.from_tensor_slices((img_class.images, img_class.shuffle_images, img_class.domains))\n",
        "\n",
        "            gpu_device = '/gpu:0'\n",
        "\n",
        "            img_and_domain = img_and_domain.shuffle(buffer_size=dataset_num, reshuffle_each_iteration=True).repeat()\n",
        "            img_and_domain = img_and_domain.map(map_func=img_class.image_processing, num_parallel_calls=AUTOTUNE).batch(self.batch_size, drop_remainder=True)\n",
        "            img_and_domain = img_and_domain.apply(prefetch_to_device(gpu_device, buffer_size=AUTOTUNE))\n",
        "\n",
        "            self.img_and_domain_iter = iter(img_and_domain)\n",
        "\n",
        "            \"\"\" Network \"\"\"\n",
        "            self.generator = Generator(self.img_size, self.img_ch, self.style_dim, max_conv_dim=self.hidden_dim, sn=False, name='Generator')\n",
        "            self.mapping_network = MappingNetwork(self.style_dim, self.hidden_dim, self.num_domains, sn=False, name='MappingNetwork')\n",
        "            self.style_encoder = StyleEncoder(self.img_size, self.style_dim, self.num_domains, max_conv_dim=self.hidden_dim, sn=False, name='StyleEncoder')\n",
        "            self.discriminator = Discriminator(self.img_size, self.num_domains, max_conv_dim=self.hidden_dim, sn=self.sn, name='Discriminator')\n",
        "\n",
        "            self.generator_ema = deepcopy(self.generator)\n",
        "            self.mapping_network_ema = deepcopy(self.mapping_network)\n",
        "            self.style_encoder_ema = deepcopy(self.style_encoder)\n",
        "\n",
        "            \"\"\" Finalize model (build) \"\"\"\n",
        "            x = np.ones(shape=[self.batch_size, self.img_size, self.img_size, self.img_ch], dtype=np.float32)\n",
        "            y = np.ones(shape=[self.batch_size, 1], dtype=np.int32)\n",
        "            z = np.ones(shape=[self.batch_size, self.latent_dim], dtype=np.float32)\n",
        "            s = np.ones(shape=[self.batch_size, self.style_dim], dtype=np.float32)\n",
        "\n",
        "            _ = self.mapping_network([z, y])\n",
        "            _ = self.mapping_network_ema([z, y])\n",
        "            _ = self.style_encoder([x, y])\n",
        "            _ = self.style_encoder_ema([x, y])\n",
        "            _ = self.generator([x, s])\n",
        "            _ = self.generator_ema([x, s])\n",
        "            _ = self.discriminator([x, y])\n",
        "\n",
        "\n",
        "            \"\"\" Optimizer \"\"\"\n",
        "            self.g_optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr, beta_1=self.beta1, beta_2=self.beta2, epsilon=1e-08)\n",
        "            self.e_optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr, beta_1=self.beta1, beta_2=self.beta2, epsilon=1e-08)\n",
        "            self.f_optimizer = tf.keras.optimizers.Adam(learning_rate=self.f_lr, beta_1=self.beta1, beta_2=self.beta2, epsilon=1e-08)\n",
        "            self.d_optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr, beta_1=self.beta1, beta_2=self.beta2, epsilon=1e-08)\n",
        "\n",
        "\n",
        "            \"\"\" Checkpoint \"\"\"\n",
        "            self.ckpt = tf.train.Checkpoint(generator=self.generator, generator_ema=self.generator_ema,\n",
        "                                            mapping_network=self.mapping_network, mapping_network_ema=self.mapping_network_ema,\n",
        "                                            style_encoder=self.style_encoder, style_encoder_ema=self.style_encoder_ema,\n",
        "                                            discriminator=self.discriminator,\n",
        "                                            g_optimizer=self.g_optimizer, e_optimizer=self.e_optimizer, f_optimizer=self.f_optimizer,\n",
        "                                            d_optimizer=self.d_optimizer)\n",
        "            self.manager = tf.train.CheckpointManager(self.ckpt, self.checkpoint_dir, max_to_keep=1)\n",
        "            self.start_iteration = 0\n",
        "\n",
        "            if self.manager.latest_checkpoint:\n",
        "                self.ckpt.restore(self.manager.latest_checkpoint).expect_partial()\n",
        "                self.start_iteration = int(self.manager.latest_checkpoint.split('-')[-1])\n",
        "                print('Latest checkpoint restored!!')\n",
        "                print('start iteration : ', self.start_iteration)\n",
        "            else:\n",
        "                print('Not restoring from saved checkpoint')\n",
        "\n",
        "        else:\n",
        "            \"\"\" Test \"\"\"\n",
        "            \"\"\" Network \"\"\"\n",
        "            self.generator_ema = Generator(self.img_size, self.img_ch, self.style_dim, max_conv_dim=self.hidden_dim, sn=False, name='Generator')\n",
        "            self.mapping_network_ema = MappingNetwork(self.style_dim, self.hidden_dim, self.num_domains, sn=False, name='MappingNetwork')\n",
        "            self.style_encoder_ema = StyleEncoder(self.img_size, self.style_dim, self.num_domains, max_conv_dim=self.hidden_dim, sn=False, name='StyleEncoder')\n",
        "\n",
        "            \"\"\" Finalize model (build) \"\"\"\n",
        "            x = np.ones(shape=[self.batch_size, self.img_size, self.img_size, self.img_ch], dtype=np.float32)\n",
        "            y = np.ones(shape=[self.batch_size, 1], dtype=np.int32)\n",
        "            z = np.ones(shape=[self.batch_size, self.latent_dim], dtype=np.float32)\n",
        "            s = np.ones(shape=[self.batch_size, self.style_dim], dtype=np.float32)\n",
        "\n",
        "            _ = self.mapping_network_ema([z, y])\n",
        "            _ = self.style_encoder_ema([x, y])\n",
        "            _ = self.generator_ema([x, s])\n",
        "\n",
        "            \"\"\" Checkpoint \"\"\"\n",
        "            self.ckpt = tf.train.Checkpoint(generator_ema=self.generator_ema,\n",
        "                                            mapping_network_ema=self.mapping_network_ema,\n",
        "                                            style_encoder_ema=self.style_encoder_ema)\n",
        "            self.manager = tf.train.CheckpointManager(self.ckpt, self.checkpoint_dir, max_to_keep=1)\n",
        "\n",
        "            if self.manager.latest_checkpoint:\n",
        "                self.ckpt.restore(self.manager.latest_checkpoint).expect_partial()\n",
        "                print('Latest checkpoint restored!!')\n",
        "            else:\n",
        "                print('Not restoring from saved checkpoint')\n",
        "\n",
        "    @tf.function\n",
        "    def g_train_step(self, x_real, y_org, y_trg, z_trgs=None, x_refs=None):\n",
        "        with tf.GradientTape(persistent=True) as g_tape:\n",
        "            if z_trgs is not None:\n",
        "                z_trg, z_trg2 = z_trgs\n",
        "            if x_refs is not None:\n",
        "                x_ref, x_ref2 = x_refs\n",
        "\n",
        "            # adversarial loss\n",
        "            if z_trgs is not None:\n",
        "                s_trg = self.mapping_network([z_trg, y_trg])\n",
        "            else:\n",
        "                s_trg = self.style_encoder([x_ref, y_trg])\n",
        "\n",
        "            x_fake = self.generator([x_real, s_trg])\n",
        "            fake_logit = self.discriminator([x_fake, y_trg])\n",
        "            g_adv_loss = self.adv_weight * generator_loss(self.gan_type, fake_logit)\n",
        "\n",
        "            # style reconstruction loss\n",
        "            s_pred = self.style_encoder([x_fake, y_trg])\n",
        "            g_sty_loss = self.sty_weight * L1_loss(s_pred, s_trg)\n",
        "\n",
        "            # diversity sensitive loss\n",
        "            if z_trgs is not None:\n",
        "                s_trg2 = self.mapping_network([z_trg2, y_trg])\n",
        "            else:\n",
        "                s_trg2 = self.style_encoder([x_ref2, y_trg])\n",
        "\n",
        "            x_fake2 = self.generator([x_real, s_trg2])\n",
        "            x_fake2 = tf.stop_gradient(x_fake2)\n",
        "            g_ds_loss = -self.ds_weight * L1_loss(x_fake, x_fake2)\n",
        "\n",
        "            # cycle-consistency loss\n",
        "            s_org = self.style_encoder([x_real, y_org])\n",
        "            x_rec = self.generator([x_fake, s_org])\n",
        "            g_cyc_loss = self.cyc_weight * L1_loss(x_rec, x_real)\n",
        "\n",
        "            regular_loss = regularization_loss(self.generator)\n",
        "\n",
        "            g_loss = g_adv_loss + g_sty_loss + g_ds_loss + g_cyc_loss + regular_loss\n",
        "\n",
        "        g_train_variable = self.generator.trainable_variables\n",
        "        g_gradient = g_tape.gradient(g_loss, g_train_variable)\n",
        "        self.g_optimizer.apply_gradients(zip(g_gradient, g_train_variable))\n",
        "\n",
        "        if z_trgs is not None:\n",
        "            f_train_variable = self.mapping_network.trainable_variables\n",
        "            e_train_variable = self.style_encoder.trainable_variables\n",
        "\n",
        "            f_gradient = g_tape.gradient(g_loss, f_train_variable)\n",
        "            e_gradient = g_tape.gradient(g_loss, e_train_variable)\n",
        "\n",
        "            self.f_optimizer.apply_gradients(zip(f_gradient, f_train_variable))\n",
        "            self.e_optimizer.apply_gradients(zip(e_gradient, e_train_variable))\n",
        "\n",
        "        return g_adv_loss, g_sty_loss, g_ds_loss, g_cyc_loss, g_loss\n",
        "\n",
        "    @tf.function\n",
        "    def d_train_step(self, x_real, y_org, y_trg, z_trg=None, x_ref=None):\n",
        "        with tf.GradientTape() as d_tape:\n",
        "\n",
        "            if z_trg is not None:\n",
        "                s_trg = self.mapping_network([z_trg, y_trg])\n",
        "            else: # x_ref is not None\n",
        "                s_trg = self.style_encoder([x_ref, y_trg])\n",
        "\n",
        "            x_fake = self.generator([x_real, s_trg])\n",
        "\n",
        "            real_logit = self.discriminator([x_real, y_org])\n",
        "            fake_logit = self.discriminator([x_fake, y_trg])\n",
        "\n",
        "            d_adv_loss = self.adv_weight * discriminator_loss(self.gan_type, real_logit, fake_logit)\n",
        "\n",
        "            if self.gan_type == 'gan-gp':\n",
        "                d_adv_loss += self.r1_weight * r1_gp_req(self.discriminator, x_real, y_org)\n",
        "\n",
        "            regular_loss = regularization_loss(self.discriminator)\n",
        "\n",
        "            d_loss = d_adv_loss + regular_loss\n",
        "\n",
        "        d_train_variable = self.discriminator.trainable_variables\n",
        "        d_gradient = d_tape.gradient(d_loss, d_train_variable)\n",
        "        self.d_optimizer.apply_gradients(zip(d_gradient, d_train_variable))\n",
        "\n",
        "        return d_adv_loss, d_loss\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # setup tensorboards\n",
        "        train_summary_writer = tf.summary.create_file_writer(self.log_dir)\n",
        "        ds_weight_init = self.ds_weight\n",
        "\n",
        "        for idx in range(self.start_iteration, self.iteration):\n",
        "            iter_start_time = time.time()\n",
        "\n",
        "            # decay weight for diversity sensitive loss\n",
        "            if self.ds_weight > 0:\n",
        "                self.ds_weight = ds_weight_init - (ds_weight_init / self.ds_iter) * idx\n",
        "\n",
        "            x_real, _, y_org = next(self.img_and_domain_iter)\n",
        "            x_ref, x_ref2, y_trg = next(self.img_and_domain_iter)\n",
        "\n",
        "            z_trg = tf.random.normal(shape=[self.batch_size, self.latent_dim])\n",
        "            z_trg2 = tf.random.normal(shape=[self.batch_size, self.latent_dim])\n",
        "\n",
        "            # update discriminator\n",
        "            d_adv_loss_latent, d_loss_latent = self.d_train_step(x_real, y_org, y_trg, z_trg=z_trg)\n",
        "            d_adv_loss_ref, d_loss_ref = self.d_train_step(x_real, y_org, y_trg, x_ref=x_ref)\n",
        "\n",
        "            # update generator\n",
        "            g_adv_loss_latent, g_sty_loss_latent, g_ds_loss_latent, g_cyc_loss_latent, g_loss_latent = self.g_train_step(x_real, y_org, y_trg, z_trgs=[z_trg, z_trg2])\n",
        "            g_adv_loss_ref, g_sty_loss_ref, g_ds_loss_ref, g_cyc_loss_ref, g_loss_ref = self.g_train_step(x_real, y_org, y_trg, x_refs=[x_ref, x_ref2])\n",
        "\n",
        "            # compute moving average of network parameters\n",
        "            moving_average(self.generator, self.generator_ema, beta=self.ema_decay)\n",
        "            moving_average(self.mapping_network, self.mapping_network_ema, beta=self.ema_decay)\n",
        "            moving_average(self.style_encoder, self.style_encoder_ema, beta=self.ema_decay)\n",
        "\n",
        "\n",
        "            if idx == 0 :\n",
        "                g_params = self.generator.count_params()\n",
        "                d_params = self.discriminator.count_params()\n",
        "                print(\"G network parameters : \", format(g_params, ','))\n",
        "                print(\"D network parameters : \", format(d_params, ','))\n",
        "                print(\"Total network parameters : \", format(g_params + d_params, ','))\n",
        "\n",
        "            # save to tensorboard\n",
        "\n",
        "            with train_summary_writer.as_default():\n",
        "                tf.summary.scalar('g/latent/adv_loss', g_adv_loss_latent, step=idx)\n",
        "                tf.summary.scalar('g/latent/sty_loss', g_sty_loss_latent, step=idx)\n",
        "                tf.summary.scalar('g/latent/ds_loss', g_ds_loss_latent, step=idx)\n",
        "                tf.summary.scalar('g/latent/cyc_loss', g_cyc_loss_latent, step=idx)\n",
        "                tf.summary.scalar('g/latent/loss', g_loss_latent, step=idx)\n",
        "\n",
        "                tf.summary.scalar('g/ref/adv_loss', g_adv_loss_ref, step=idx)\n",
        "                tf.summary.scalar('g/ref/sty_loss', g_sty_loss_ref, step=idx)\n",
        "                tf.summary.scalar('g/ref/ds_loss', g_ds_loss_ref, step=idx)\n",
        "                tf.summary.scalar('g/ref/cyc_loss', g_cyc_loss_ref, step=idx)\n",
        "                tf.summary.scalar('g/ref/loss', g_loss_ref, step=idx)\n",
        "\n",
        "                tf.summary.scalar('g/ds_weight', self.ds_weight, step=idx)\n",
        "\n",
        "                tf.summary.scalar('d/latent/adv_loss', d_adv_loss_latent, step=idx)\n",
        "                tf.summary.scalar('d/latent/loss', d_loss_latent, step=idx)\n",
        "\n",
        "                tf.summary.scalar('d/ref/adv_loss', d_adv_loss_ref, step=idx)\n",
        "                tf.summary.scalar('d/ref/loss', d_loss_ref, step=idx)\n",
        "\n",
        "            # save every self.save_freq\n",
        "            if np.mod(idx + 1, self.save_freq) == 0:\n",
        "                self.manager.save(checkpoint_number=idx + 1)\n",
        "\n",
        "            # save every self.print_freq\n",
        "            if np.mod(idx + 1, self.print_freq) == 0:\n",
        "\n",
        "\n",
        "                latent_fake_save_path = './{}/latent_{:07d}.jpg'.format(self.sample_dir, idx + 1)\n",
        "                ref_fake_save_path = './{}/ref_{:07d}.jpg'.format(self.sample_dir, idx + 1)\n",
        "\n",
        "                self.latent_canvas(x_real, latent_fake_save_path)\n",
        "                self.refer_canvas(x_real, x_ref, y_trg, ref_fake_save_path, img_num=5)\n",
        "\n",
        "            print(\"iter: [%6d/%6d] time: %4.4f d_loss: %.8f, g_loss: %.8f\" % (\n",
        "            idx, self.iteration, time.time() - iter_start_time, d_loss_latent+d_loss_ref, g_loss_latent+g_loss_ref))\n",
        "\n",
        "        # save model for final step\n",
        "        self.manager.save(checkpoint_number=self.iteration)\n",
        "\n",
        "        print(\"Total train time: %4.4f\" % (time.time() - start_time))\n",
        "\n",
        "    @property\n",
        "    def model_dir(self):\n",
        "\n",
        "        if self.sn:\n",
        "            sn = '_sn'\n",
        "        else:\n",
        "            sn = ''\n",
        "\n",
        "        return \"{}_{}_{}{}\".format(self.model_name, self.dataset_name, self.gan_type, sn)\n",
        "\n",
        "    def refer_canvas(self, x_real, x_ref, y_trg, path, img_num):\n",
        "        if type(img_num) == list:\n",
        "            # In test phase\n",
        "            src_img_num = img_num[0]\n",
        "            ref_img_num = img_num[1]\n",
        "        else:\n",
        "            src_img_num = min(img_num, self.batch_size)\n",
        "            ref_img_num = min(img_num, self.batch_size)\n",
        "\n",
        "        x_real = x_real[:src_img_num]\n",
        "        x_ref = x_ref[:ref_img_num]\n",
        "        y_trg = y_trg[:ref_img_num]\n",
        "\n",
        "        canvas = PIL.Image.new('RGB', (self.img_size * (src_img_num + 1) + 10, self.img_size * (ref_img_num + 1) + 10),\n",
        "                               'white')\n",
        "\n",
        "        x_real_post = postprocess_images(x_real)\n",
        "        x_ref_post = postprocess_images(x_ref)\n",
        "\n",
        "        for col, src_image in enumerate(list(x_real_post)):\n",
        "            canvas.paste(PIL.Image.fromarray(np.uint8(src_image), 'RGB'), ((col + 1) * self.img_size + 10, 0))\n",
        "\n",
        "        for row, dst_image in enumerate(list(x_ref_post)):\n",
        "            canvas.paste(PIL.Image.fromarray(np.uint8(dst_image), 'RGB'), (0, (row + 1) * self.img_size + 10))\n",
        "\n",
        "            row_images = np.stack([dst_image] * src_img_num)\n",
        "            row_images = preprocess_fit_train_image(row_images)\n",
        "            row_images_y = np.stack([y_trg[row]] * src_img_num)\n",
        "\n",
        "            s_trg = self.style_encoder_ema([row_images, row_images_y])\n",
        "            row_fake_images = postprocess_images(self.generator_ema([x_real, s_trg]))\n",
        "\n",
        "            for col, image in enumerate(list(row_fake_images)):\n",
        "                canvas.paste(PIL.Image.fromarray(np.uint8(image), 'RGB'),\n",
        "                             ((col + 1) * self.img_size + 10, (row + 1) * self.img_size + 10))\n",
        "\n",
        "        canvas.save(path)\n",
        "\n",
        "    def latent_canvas(self, x_real, path):\n",
        "        canvas = PIL.Image.new('RGB', (self.img_size * (self.num_domains + 1) + 10, self.img_size * self.num_style), 'white')\n",
        "\n",
        "        x_real = tf.expand_dims(x_real[0], axis=0)\n",
        "        src_image = postprocess_images(x_real)[0]\n",
        "        canvas.paste(PIL.Image.fromarray(np.uint8(src_image), 'RGB'), (0, 0))\n",
        "\n",
        "        domain_fix_list = tf.constant([idx for idx in range(self.num_domains)])\n",
        "\n",
        "        z_trgs = tf.random.normal(shape=[self.num_style, self.latent_dim])\n",
        "\n",
        "        for row in range(self.num_style):\n",
        "            z_trg = tf.expand_dims(z_trgs[row], axis=0)\n",
        "\n",
        "            for col, y_trg in enumerate(list(domain_fix_list)):\n",
        "                y_trg = tf.reshape(y_trg, shape=[1, 1])\n",
        "                s_trg = self.mapping_network_ema([z_trg, y_trg])\n",
        "                x_fake = self.generator_ema([x_real, s_trg])\n",
        "                x_fake = postprocess_images(x_fake)\n",
        "\n",
        "                col_image = x_fake[0]\n",
        "\n",
        "                canvas.paste(PIL.Image.fromarray(np.uint8(col_image), 'RGB'), ((col + 1) * self.img_size + 10, row * self.img_size))\n",
        "\n",
        "        canvas.save(path)\n",
        "\n",
        "    def test(self, merge=True, merge_size=0):\n",
        "        source_path = os.path.join(self.test_dataset_path, 'src_imgs')\n",
        "        source_images = glob(os.path.join(source_path, '*.png')) + glob(os.path.join(source_path, '*.jpg'))\n",
        "        source_images = sorted(source_images)\n",
        "\n",
        "        # reference-guided synthesis\n",
        "        print('reference-guided synthesis')\n",
        "        reference_path = os.path.join(self.test_dataset_path, 'ref_imgs')\n",
        "        reference_images = []\n",
        "        reference_domain = []\n",
        "\n",
        "        for idx, domain in enumerate(self.domain_list):\n",
        "            image_list = glob(os.path.join(reference_path, domain) + '/*.png') + glob(\n",
        "                os.path.join(reference_path, domain) + '/*.jpg')\n",
        "            image_list = sorted(image_list)\n",
        "            domain_list = [[idx]] * len(image_list)  # [ [0], [0], ... , [0] ]\n",
        "\n",
        "            reference_images.extend(image_list)\n",
        "            reference_domain.extend(domain_list)\n",
        "\n",
        "        if merge:\n",
        "            src_img = None\n",
        "            ref_img = None\n",
        "            ref_img_domain = None\n",
        "\n",
        "            if merge_size == 0:\n",
        "                # [len_src_imgs : len_ref_imgs] matching\n",
        "                for src_idx, src_img_path in tenumerate(source_images):\n",
        "                    src_name, src_extension = os.path.splitext(src_img_path)\n",
        "                    src_name = os.path.basename(src_name)\n",
        "\n",
        "                    src_img_ = load_images(src_img_path, self.img_size, self.img_ch)  # [img_size, img_size, img_ch]\n",
        "                    src_img_ = tf.expand_dims(src_img_, axis=0)\n",
        "\n",
        "                    if src_idx == 0:\n",
        "                        src_img = src_img_\n",
        "                    else:\n",
        "                        src_img = tf.concat([src_img, src_img_], axis=0)\n",
        "\n",
        "                for ref_idx, (ref_img_path, ref_img_domain_) in tenumerate(zip(reference_images, reference_domain)):\n",
        "                    ref_name, ref_extension = os.path.splitext(ref_img_path)\n",
        "                    ref_name = os.path.basename(ref_name)\n",
        "\n",
        "                    ref_img_ = load_images(ref_img_path, self.img_size, self.img_ch)  # [img_size, img_size, img_ch]\n",
        "                    ref_img_ = tf.expand_dims(ref_img_, axis=0)\n",
        "                    ref_img_domain_ = tf.expand_dims(ref_img_domain_, axis=0)\n",
        "\n",
        "                    if ref_idx == 0:\n",
        "                        ref_img = ref_img_\n",
        "                        ref_img_domain = ref_img_domain_\n",
        "                    else:\n",
        "                        ref_img = tf.concat([ref_img, ref_img_], axis=0)\n",
        "                        ref_img_domain = tf.concat([ref_img_domain, ref_img_domain_], axis=0)\n",
        "\n",
        "                save_path = './{}/ref_all.jpg'.format(self.result_dir)\n",
        "\n",
        "                self.refer_canvas(src_img, ref_img, ref_img_domain, save_path,\n",
        "                                  img_num=[len(source_images), len(reference_images)])\n",
        "\n",
        "            else:\n",
        "                # [merge_size : merge_size] matching\n",
        "                src_size = 0\n",
        "                for src_idx, src_img_path in tenumerate(source_images):\n",
        "                    src_name, src_extension = os.path.splitext(src_img_path)\n",
        "                    src_name = os.path.basename(src_name)\n",
        "\n",
        "                    src_img_ = load_images(src_img_path, self.img_size, self.img_ch)  # [img_size, img_size, img_ch]\n",
        "                    src_img_ = tf.expand_dims(src_img_, axis=0)\n",
        "\n",
        "                    if src_size < merge_size:\n",
        "                        if src_idx % merge_size == 0:\n",
        "                            src_img = src_img_\n",
        "                        else:\n",
        "                            src_img = tf.concat([src_img, src_img_], axis=0)\n",
        "                        src_size += 1\n",
        "\n",
        "                        if src_size == merge_size:\n",
        "                            src_size = 0\n",
        "\n",
        "                            ref_size = 0\n",
        "                            for ref_idx, (ref_img_path, ref_img_domain_) in enumerate(\n",
        "                                    zip(reference_images, reference_domain)):\n",
        "                                ref_name, ref_extension = os.path.splitext(ref_img_path)\n",
        "                                ref_name = os.path.basename(ref_name)\n",
        "\n",
        "                                ref_img_ = load_images(ref_img_path, self.img_size,\n",
        "                                                       self.img_ch)  # [img_size, img_size, img_ch]\n",
        "                                ref_img_ = tf.expand_dims(ref_img_, axis=0)\n",
        "                                ref_img_domain_ = tf.expand_dims(ref_img_domain_, axis=0)\n",
        "\n",
        "                                if ref_size < merge_size:\n",
        "                                    if ref_idx % merge_size == 0:\n",
        "                                        ref_img = ref_img_\n",
        "                                        ref_img_domain = ref_img_domain_\n",
        "                                    else:\n",
        "                                        ref_img = tf.concat([ref_img, ref_img_], axis=0)\n",
        "                                        ref_img_domain = tf.concat([ref_img_domain, ref_img_domain_], axis=0)\n",
        "\n",
        "                                    ref_size += 1\n",
        "                                    if ref_size == merge_size:\n",
        "                                        ref_size = 0\n",
        "\n",
        "                                        save_path = './{}/ref_{}_{}.jpg'.format(self.result_dir, src_idx + 1, ref_idx + 1)\n",
        "\n",
        "                                        self.refer_canvas(src_img, ref_img, ref_img_domain, save_path,\n",
        "                                                          img_num=merge_size)\n",
        "\n",
        "        else:\n",
        "            # [1:1] matching\n",
        "            for src_img_path in tqdm(source_images):\n",
        "                src_name, src_extension = os.path.splitext(src_img_path)\n",
        "                src_name = os.path.basename(src_name)\n",
        "\n",
        "                src_img = load_images(src_img_path, self.img_size, self.img_ch)  # [img_size, img_size, img_ch]\n",
        "                src_img = tf.expand_dims(src_img, axis=0)\n",
        "\n",
        "                for ref_img_path, ref_img_domain in zip(reference_images, reference_domain):\n",
        "                    ref_name, ref_extension = os.path.splitext(ref_img_path)\n",
        "                    ref_name = os.path.basename(ref_name)\n",
        "\n",
        "                    ref_img = load_images(ref_img_path, self.img_size, self.img_ch)  # [img_size, img_size, img_ch]\n",
        "                    ref_img = tf.expand_dims(ref_img, axis=0)\n",
        "                    ref_img_domain = tf.expand_dims(ref_img_domain, axis=0)\n",
        "\n",
        "                    save_path = './{}/ref_{}_{}{}'.format(self.result_dir, src_name, ref_name, src_extension)\n",
        "\n",
        "                    self.refer_canvas(src_img, ref_img, ref_img_domain, save_path, img_num=1)\n",
        "\n",
        "        # latent-guided synthesis\n",
        "        print('latent-guided synthesis')\n",
        "        for src_img_path in tqdm(source_images):\n",
        "            src_name, src_extension = os.path.splitext(src_img_path)\n",
        "            src_name = os.path.basename(src_name)\n",
        "\n",
        "            src_img = load_images(src_img_path, self.img_size, self.img_ch)  # [img_size, img_size, img_ch]\n",
        "            src_img = tf.expand_dims(src_img, axis=0)\n",
        "\n",
        "            save_path = './{}/latent_{}{}'.format(self.result_dir, src_name, src_extension)\n",
        "\n",
        "            self.latent_canvas(src_img, save_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}